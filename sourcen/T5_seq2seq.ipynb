{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a570bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
    "from datasets import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "569fc84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfBibTex = pd.read_csv('bibTex.csv', encoding = \"ansi\", on_bad_lines='skip', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d8770d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'input_text': [],\n",
    "    'target_text': []\n",
    "}\n",
    "\n",
    "data['input_text'] = dfBibTex['Referenzstring'].tolist()\n",
    "data['target_text'] = dfBibTex['BibTeX'].tolist()\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "\n",
    "split_dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = split_dataset['train']\n",
    "val_dataset = split_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aef620ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            input_text  \\\n",
      "671  @inproceedings{ahsan-etal-2024-multimodal,\\n  ...   \n",
      "286  @inproceedings{shah-etal-2024-parrottts,\\n    ...   \n",
      "728  @inproceedings{k-etal-2024-dataset,\\n    title...   \n",
      "434  @inproceedings{fily-etal-2024-establishing,\\n ...   \n",
      "734  @inproceedings{b-etal-2024-findings-shared,\\n ...   \n",
      "..                                                 ...   \n",
      "536  @inproceedings{koto-etal-2024-zero,\\n    title...   \n",
      "346  @inproceedings{chen-etal-2024-learning,\\n    t...   \n",
      "247  @inproceedings{ohman-etal-2024-emotionarcs,\\n ...   \n",
      "350  @inproceedings{lin-etal-2024-indivec,\\n    tit...   \n",
      "60   @inproceedings{miranda-2024-allen,\\n    title ...   \n",
      "\n",
      "                                           target_text  \n",
      "671  Shawly Ahsan, Eftekhar Hossain, Omar Sharif, A...  \n",
      "286  Neil Shah, Saiteja Kosgi, Vishal Tambrahalli, ...  \n",
      "728  Devika K, Hariprasath .s.b, Haripriya B, Vigne...  \n",
      "434  Maxime Fily, Guillaume Wisniewski, Severine Gu...  \n",
      "734  Premjith B, Jyothish G, Sowmya V, Bharathi Raj...  \n",
      "..                                                 ...  \n",
      "536  Fajri Koto, Tilman Beck, Zeerak Talat, Iryna G...  \n",
      "346  Lihu Chen, Gael Varoquaux, and Fabian Suchanek...  \n",
      "247  Emily Ohman, Yuri Bizzoni, Pascale Feldkamp Mo...  \n",
      "350  Luyang Lin, Lingzhi Wang, Xiaoyan Zhao, Jing L...  \n",
      "60   Lester James Miranda. Allen institute for AI @...  \n",
      "\n",
      "[155 rows x 2 columns]\n",
      "Dataset({\n",
      "    features: ['input_text', 'target_text', '__index_level_0__'],\n",
      "    num_rows: 155\n",
      "})\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1667c34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Tokenisierung\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c2ef883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = examples['input_text']\n",
    "    inputs = ['translate bibliographyEntry to BibTeX:' + doc for doc in examples['input_text']]\n",
    "    targets = examples['target_text']\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding='max_length')\n",
    "    labels = tokenizer(targets, max_length=512, truncation=True, padding='max_length')\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85f06587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ceebde554314dd5b0de75e00c07981a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/616 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5e0fbf06e9449b39c35d7bf4023f86e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_eval_dataset = val_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f282124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_text': 'Nikolaos Aletras and Orphee De Clercq, editors. Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations, St. Julians, Malta, March 2024. Association for Computational Linguistics. URL: https://aclanthology.org/2024.eacl-demo.0.\\n', 'target_text': '@proceedings{eacl-2024-european,\\n    title = \"Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations\",\\n    editor = \"Aletras, Nikolaos  and\\n      De Clercq, Orphee\",\\n    month = mar,\\n    year = \"2024\",\\n    address = \"St. Julians, Malta\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2024.eacl-demo.0\",\\n}\\n', 'input_ids': [13959, 24765, 5984, 16924, 651, 12, 3, 27915, 382, 15, 4, 10, 567, 12027, 521, 32, 7, 15345, 1313, 7, 11, 955, 102, 88, 15, 374, 4779, 49, 75, 1824, 6, 18008, 5, 24569, 13, 8, 507, 189, 4379, 13, 8, 1611, 8647, 13, 8, 2125, 21, 638, 31148, 138, 6741, 1744, 3040, 7, 10, 2149, 15782, 29, 3109, 10872, 6, 472, 5, 20080, 7, 6, 21384, 6, 1332, 460, 2266, 5, 2125, 21, 638, 31148, 138, 6741, 1744, 3040, 7, 5, 8889, 10, 4893, 1303, 9, 4651, 29, 189, 1863, 5, 1677, 20173, 2266, 5, 15, 9, 75, 40, 18, 1778, 32, 5, 632, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [3320, 1409, 75, 6958, 53, 7, 2, 15, 9, 75, 40, 7988, 2266, 18, 28188, 152, 6, 2233, 3274, 96, 3174, 75, 6958, 53, 7, 13, 8, 507, 189, 4379, 13, 8, 1611, 8647, 13, 8, 2125, 21, 638, 31148, 138, 6741, 1744, 3040, 7, 10, 2149, 15782, 29, 3109, 10872, 1686, 6005, 3274, 96, 188, 109, 1313, 7, 6, 28584, 32, 7, 11, 374, 4779, 49, 75, 1824, 6, 955, 102, 88, 15, 1686, 847, 3274, 3157, 6, 215, 3274, 96, 19818, 20364, 6, 1115, 3274, 96, 134, 17, 5, 20080, 7, 6, 21384, 1686, 14859, 3274, 96, 25714, 21, 638, 31148, 138, 6741, 1744, 3040, 7, 1686, 3, 16137, 3274, 96, 5948, 7, 1303, 9, 4651, 29, 189, 1863, 5, 1677, 20173, 2266, 5, 15, 9, 75, 40, 18, 1778, 32, 5, 632, 1686, 3, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3536a0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "model.to(device)\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='./results',\n",
    "    eval_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=10,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da3f0997",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='390' max='390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [390/390 1:12:14, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.641047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.138298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.888591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.722874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.605539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.531891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.484598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.453200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.436056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.429324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BibliographyEntry to BibTeX:Brown, B. (2021), New findings, Important Journal, 10(2), 200-220.\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "# Testen\n",
    "test_input = \"\"\"Brown, B. (2021). New findings. Important Journal, 10(2), 200-220.\"\"\"\n",
    "inputs = tokenizer.encode(\"translate bibliographyEntry to BibTeX:\" + test_input, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
    "outputs = model.generate(inputs, max_length=512, num_beams=4, early_stopping=True)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ff5ad3",
   "metadata": {},
   "source": [
    "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select) -> Dieser Fehler tritt auf, wenn Tensoren auf verschiedenen Geräten (z. B. CPU und GPU) platziert sind und eine Operation ausgeführt wird, die Tensoren erwartet, die alle auf dem gleichen Gerät sind. Um diesen Fehler zu beheben, müssen wir sicherstellen, dass sowohl das Modell als auch die Tensoren (inputs) auf demselben Gerät (CPU oder GPU) sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f34d83e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> BibliographyEntry to BibTeX:Brown, B. (2021), New findings, Important Journal, 10(2), 200-220.</s>\n"
     ]
    }
   ],
   "source": [
    "test_input = \"\"\"Brown, B. (2021). New findings. Important Journal, 10(2), 200-220.\"\"\"\n",
    "inputs = tokenizer.encode(\"translate bibliographyEntry to BibTeX:\" + test_input, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
    "outputs = model.generate(inputs, max_length=512, num_beams=4, early_stopping=True)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa157339",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
