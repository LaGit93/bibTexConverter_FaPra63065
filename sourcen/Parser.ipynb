{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9ef1f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wenn man den typen bestimmte hat, sollte man zunächst alle Pflicht-Felder des Bibtex-Eintrages raussuchen und bestimmen.\n",
    "#Dazu die Pflichtattribute in einer Schleife durchgehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bde3f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "torch.cuda.is_available()\n",
    "from transformers import pipeline\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad55d2b1",
   "metadata": {},
   "source": [
    "@book{advanced_physics, author = {Stephen Hawking and Brian Greene and Maria Trump and Susan Soy}, title = {Advanced Concepts in Theoretical Physics}, publisher = {Cambridge University Press}, year = {2025}, edition = {3}, volume = {1}, series = {Advanced Studies in Physics}, address = {Cambridge, UK}, month = {May}, note = {A seminal work in the field of theoretical physics}, isbn = {978-0-521-76948-0}, doi = {10.1017/example.book.2025}, url = {https://www.cambridge.org/advanced_physics}, annote = {Widely cited in the physics community}, abstract = {This book explores cutting-edge theories and concepts in theoretical physics...}, keywords = {Theoretical Physics, Quantum Mechanics, String Theory}, language = {English}, price = {75.00}, size = {600 pages}, lccn = {2020934576}, mrnumber = {MR3070071} }\n",
    "\n",
    "@article{quantum_entanglement,\n",
    "  author        = {Albert Einstein and Boris Podolsky and Nathan Rosen},\n",
    "  title         = {Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?},\n",
    "  journal       = {Physical Review},\n",
    "  year          = {1935},\n",
    "  volume        = {47},\n",
    "  number        = {10},\n",
    "  pages         = {777-780},\n",
    "  month         = {May},\n",
    "  note          = {EPR Paradox paper, fundamental for quantum mechanics},\n",
    "  doi           = {10.1103/PhysRev.47.777},\n",
    "  url           = {https://journals.aps.org/pr/abstract/10.1103/PhysRev.47.777},\n",
    "  abstract      = {In this paper, the authors discuss the EPR paradox and challenge the completeness of quantum mechanics...},\n",
    "  keywords      = {Quantum Mechanics, EPR Paradox, Physical Reality},\n",
    "  language      = {English},\n",
    "  publisher     = {American Physical Society}\n",
    "}\n",
    "\n",
    "@inproceedings{deep_learning,\n",
    "  author        = {Geoffrey Hinton and Yoshua Bengio and Yann LeCun},\n",
    "  title         = {Deep Learning for Artificial Intelligence},\n",
    "  booktitle     = {Proceedings of the IEEE International Conference on Neural Networks},\n",
    "  year          = {2021},\n",
    "  editor        = {Jane Smith and John Doe},\n",
    "  volume        = {1},\n",
    "  number = {5},\n",
    "  series        = {Advances in Neural Information Processing},\n",
    "  pages         = {100-120},\n",
    "  address       = {Montreal, Canada},\n",
    "  month         = {December},\n",
    "  organization  = {IEEE},\n",
    "  publisher     = {IEEE Press},\n",
    "  note          = {Keynote paper on recent advancements in deep learning},\n",
    "  isbn          = {978-1-5386-4637-1},\n",
    "  doi           = {10.1109/ICNN.2021.9483948},\n",
    "  url           = {https://ieeexplore.ieee.org/document/9483948},\n",
    "  annote        = {A seminal work on how deep learning transforms AI},\n",
    "  abstract      = {This paper explores cutting-edge deep learning techniques and their impact on the development of artificial intelligence...},\n",
    "  keywords      = {Deep Learning, Artificial Intelligence, Neural Networks},\n",
    "  language      = {English}\n",
    "}\n",
    "\n",
    "\n",
    "@incollection{quantum_computation,\n",
    "  author        = {Michael A. Nielsen and Isaac L. Chuang},\n",
    "  title         = {Quantum Computation and Quantum Information},\n",
    "  booktitle     = {Handbook of Quantum Information Science},\n",
    "  publisher     = {Springer},\n",
    "  year          = {2026},\n",
    "  editor        = {Charles H. Bennett and David P. DiVincenzo},\n",
    "  volume        = {4},\n",
    "  series        = {Quantum Science and Technology},\n",
    "  chapter       = {10},\n",
    "  pages         = {250-300},\n",
    "  address       = {Berlin, Germany},\n",
    "  month         = {October},\n",
    "  note          = {A comprehensive overview of the fundamentals of quantum computation},\n",
    "  isbn          = {978-3-540-88702-7},\n",
    "  doi           = {10.1007/springerreference_303198},\n",
    "  url           = {https://www.springer.com/gp/book/9783540887027},\n",
    "  annote        = {Essential reading for researchers entering the field of quantum information},\n",
    "  abstract      = {This chapter delves into the principles of quantum computing, offering an accessible yet thorough introduction...},\n",
    "  keywords      = {Quantum Computing, Quantum Information, Computational Models},\n",
    "  language      = {English},\n",
    "  price         = {45.00},\n",
    "  size          = {50 pages}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b93a7979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(93, 100), match=' (Eds.)'>\n"
     ]
    }
   ],
   "source": [
    "#RegEx zum FInden der Seiten\n",
    "pageFinder = \", (?:pp\\.? )?\\d+-\\d+,\"\n",
    "doi1 = \"https:\\/\\/doi\\.org\"\n",
    "doi2 = \"DOI:\"\n",
    "\n",
    "#if havard und book:\n",
    "volume = \", \\d+,\"\n",
    "number = \", \\d+,\"\n",
    "edition1 = \"(?:[1-9]\\d*th|11th|12th|13th|[1-9]\\d*(?:st|nd|rd)) ed\\.\"\n",
    "edition2 = \"(?:[1-9]\\d*th|11th|12th|13th|[1-9]\\d*(?:st|nd|rd)) edn\\.\"\n",
    "\n",
    "#if APA or Havard then\n",
    "volume = \"\\(Vol\\. \\d+\" #für Volume und number noch als Bedingung, dass es nach Titel stehen muss, also Index > Titel-Index\n",
    "number = \"Issue \\d+\"\n",
    "yearApaHavard = \"\\(\\d{4}\\)\"\n",
    "editorRegEx = \" (\\()?(Eds\\.|Eds|Ed|ed|Ed\\.|ed\\.|eds\\.|editor|editors|edited by )(\\))?\"\n",
    "\n",
    "#editor bei anderen\n",
    "\n",
    "\n",
    "#Beachte: Editor und Edition werden oft mit gleichen Abkürzungen versehen, auch im gleichen Stil! Nur Edition wird oft\n",
    "#klein geschrieben. Daher zustzlich prüfen, ob NER das als Person erkennt.\n",
    "\n",
    "#Beachte: ieee und mla trennen mit , und nicht mit .\n",
    "#if ieee and mla\n",
    "volumeIeeeMla = \", vol\\. \\d+\" \n",
    "noIeeeMla = \", no\\. \\d+\"\n",
    "\n",
    "etAl = \"et al.\"\n",
    "\n",
    "yearACM = \"\\. \\d{4}\\.\"\n",
    "\n",
    "#Man sollte zunächst die Felder extrahieren, die zu 100% sicher erkennen kann wie Volume oder Number, doi, Autoren...-> \n",
    "#Titel, booktitle, series und journal danach\n",
    "\n",
    "#man sollte eine Überdeckungsprüfung machen: Also Bspw. sagt Space im Bereich 25-50 ist eine Orga, Regex sagt, \n",
    "#dort ist ein (Eds.)\n",
    "#zu finden und Huggingface sagt, von 25-45 ist was. Dann sollte der minimalteste Wert und maximalste Wert \n",
    "#genommen werden und so lange nach links und analog nach rechts gehen, bis wieder ein Punkt kommt.\n",
    "# Da erkannte Felder aus dem String entfernt werden, muss der String am Ende leer sein. \n",
    "#Daher sollten zunächste die Dinge ausgeschnitten werden wo der Algo sich am sichersten ist\n",
    "#TODO: Grundsätzliche Reihenfolge der BibTex-Einträge ermitteln.\n",
    "#TODO: Für jede Extrahierung eines Feldes eine eigene Unterroutine schreiben? -> In der Oberschleife sollte Style sein\n",
    "\n",
    "\n",
    "\n",
    "print(re.search(editorRegEx, \"Singh, S. K., Kumar, S., & Mehra, P. S. (2023). Chapter Title. In Johnson, E. F. & Lee, R. H. (Eds.), Book\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ddfd2554",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"Hawking, S., Greene, B., Trump, M. and Soy, S. (2025). Advanced Concepts and John Miller in Theoretical Physics (3rd ed., Vol. 1). Cambridge University Press. https://doi.org/10.1017/example.book.2025\"\n",
    "text = \"Singh, S. K., Kumar, S., & Mehra, P. S. (2023). Chat GPT & Google Bard AI: A Review. 2023 International Conference on IoT, Communication and Automation Technology (ICICAT), 1–6. https://doi.org/10.1109/ICICAT57735.2023.10263706\"\n",
    "text = \"Singh, S. K., Kumar, S., & Mehra, P. S. (2023). An new model for nuclear Energy. In Johnson, E. F. & Lee, R. H. (Eds.), Nuclear Energy Today. Publisher Name.\"\n",
    "#text = \"Singh, S. K. and Peterman, P. (2023). Chapter and Title. Trump, M. and Soy, S. Book Title. Publisher Name.\"\n",
    "#text = \"S. K. Singh, S. Kumar & P. S. Mehra, (2023). in Wonderland. In F. Johnson & L. Lee (Eds.), Book Title. Publisher Name.\"\n",
    "#text = \"F Johnson & L Lee (Eds.)\"\n",
    "#text = \"Tu Anh Nguyen, Eugene Kharitonov, Jade Copet, Yossi Adi, Wei-Ning Hsu, Ali Elkahky, Paden Tomasello, Robin Algayres, Benoît Sagot, Abdelrahman Mohamed, and Emmanuel Dupoux. 2023. Generative spoken dialogue language modeling. Transactions of the Association for Computational Linguistics 11, (2023), 250–266. URL: https://aclanthology.org/2023.tacl-1.15, doi:10.1162/tacl_a_00545\"\n",
    "#text = \"Hinton G, Bengio Y, LeCun Y (2021) Deep Learning for Artificial Intelligence. In: Smith J, Doe J (eds) Proceedings of the IEEE International Conference on Neural Networks. IEEE Press, Montreal, Canada, pp 100–120\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8acde04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "C:\\Users\\larsl\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singh, S. K., Kumar, S., & Mehra, P. S. (2023). An new model for nuclear Energy. In Johnson, E. F. & Lee, R. H. (Eds.), Nuclear Energy Today. Publisher Name.\n",
      "   entity_group     score                  word  start  end\n",
      "0           PER  0.999318                 Singh      0    5\n",
      "1           PER  0.996027                     S      7    8\n",
      "2           PER  0.997318                     K     10   11\n",
      "3           PER  0.999508                 Kumar     14   19\n",
      "4           PER  0.997833                     S     21   22\n",
      "5           PER  0.989305                 Mehra     27   32\n",
      "6           PER  0.998831                     P     34   35\n",
      "7           PER  0.997961                     S     37   38\n",
      "8          MISC  0.566246                Energy     73   79\n",
      "9           PER  0.999361               Johnson     84   91\n",
      "10          PER  0.992642                     E     93   94\n",
      "11          PER  0.985034                     F     96   97\n",
      "12          PER  0.998692                   Lee    101  104\n",
      "13          PER  0.996748                     R    106  107\n",
      "14          PER  0.991992                     H    109  110\n",
      "15          ORG  0.830442  Nuclear Energy Today    120  140\n",
      "   entity_group     score     word  start  end\n",
      "0           PER  0.999318    Singh      0    5\n",
      "1           PER  0.996027        S      7    8\n",
      "2           PER  0.997318        K     10   11\n",
      "3           PER  0.999508    Kumar     14   19\n",
      "4           PER  0.997833        S     21   22\n",
      "5           PER  0.989305    Mehra     27   32\n",
      "6           PER  0.998831        P     34   35\n",
      "7           PER  0.997961        S     37   38\n",
      "8           PER  0.999361  Johnson     84   91\n",
      "9           PER  0.992642        E     93   94\n",
      "10          PER  0.985034        F     96   97\n",
      "11          PER  0.998692      Lee    101  104\n",
      "12          PER  0.996748        R    106  107\n",
      "13          PER  0.991992        H    109  110\n",
      "getAuthorsAndEditors: textBetweenNames: , \n",
      "getAuthorsAndEditors: Author: Singh\n",
      "getAuthorsAndEditors: onlyPunctuation: True\n",
      "getAuthorsAndEditors: onlyAnd: False\n",
      "getAuthorsAndEditors: nothing: False\n",
      "getAuthorsAndEditors: textBetweenNames: . \n",
      "getAuthorsAndEditors: Author: S\n",
      "getAuthorsAndEditors: onlyPunctuation: True\n",
      "getAuthorsAndEditors: onlyAnd: False\n",
      "getAuthorsAndEditors: nothing: False\n",
      "getAuthorsAndEditors: textBetweenNames: ., \n",
      "getAuthorsAndEditors: Author: K\n",
      "getAuthorsAndEditors: onlyPunctuation: True\n",
      "getAuthorsAndEditors: onlyAnd: False\n",
      "getAuthorsAndEditors: nothing: False\n",
      "getAuthorsAndEditors: textBetweenNames: , \n",
      "getAuthorsAndEditors: Author: Kumar\n",
      "getAuthorsAndEditors: onlyPunctuation: True\n",
      "getAuthorsAndEditors: onlyAnd: False\n",
      "getAuthorsAndEditors: nothing: False\n",
      "getAuthorsAndEditors: textBetweenNames: ., & \n",
      "getAuthorsAndEditors: Author: S\n",
      "getAuthorsAndEditors: onlyPunctuation: False\n",
      "getAuthorsAndEditors: onlyAnd: True\n",
      "getAuthorsAndEditors: nothing: False\n",
      "getAuthorsAndEditors: textBetweenNames: , \n",
      "getAuthorsAndEditors: Author: Mehra\n",
      "getAuthorsAndEditors: onlyPunctuation: True\n",
      "getAuthorsAndEditors: onlyAnd: False\n",
      "getAuthorsAndEditors: nothing: False\n",
      "getAuthorsAndEditors: textBetweenNames: . \n",
      "getAuthorsAndEditors: Author: P\n",
      "getAuthorsAndEditors: onlyPunctuation: True\n",
      "getAuthorsAndEditors: onlyAnd: False\n",
      "getAuthorsAndEditors: nothing: False\n",
      "getAuthorsAndEditors: textBetweenNames: . (2023). An new model for nuclear Energy. In \n",
      "getAuthorsAndEditors: Author: S\n",
      "getAuthorsAndEditors: onlyPunctuation: False\n",
      "getAuthorsAndEditors: onlyAnd: False\n",
      "getAuthorsAndEditors: nothing: True\n",
      "getAuthorsAndEditors: authorsDetected: True\n",
      "getAuthorsAndEditors: is_Editor: False\n",
      "getAuthorsAndEditors: chainStartIndex: 0\n",
      "getAuthorsAndEditors: textBetweenNames: , \n",
      "getAuthorsAndEditors: Author: Johnson\n",
      "getAuthorsAndEditors: onlyPunctuation: True\n",
      "getAuthorsAndEditors: onlyAnd: False\n",
      "getAuthorsAndEditors: nothing: False\n",
      "getAuthorsAndEditors: textBetweenNames: . \n",
      "getAuthorsAndEditors: Author: E\n",
      "getAuthorsAndEditors: onlyPunctuation: True\n",
      "getAuthorsAndEditors: onlyAnd: False\n",
      "getAuthorsAndEditors: nothing: False\n",
      "getAuthorsAndEditors: textBetweenNames: . & \n",
      "getAuthorsAndEditors: Author: F\n",
      "getAuthorsAndEditors: onlyPunctuation: False\n",
      "getAuthorsAndEditors: onlyAnd: True\n",
      "getAuthorsAndEditors: nothing: False\n",
      "getAuthorsAndEditors: textBetweenNames: , \n",
      "getAuthorsAndEditors: Author: Lee\n",
      "getAuthorsAndEditors: onlyPunctuation: True\n",
      "getAuthorsAndEditors: onlyAnd: False\n",
      "getAuthorsAndEditors: nothing: False\n",
      "getAuthorsAndEditors: textBetweenNames: . \n",
      "getAuthorsAndEditors: Author: R\n",
      "getAuthorsAndEditors: onlyPunctuation: True\n",
      "getAuthorsAndEditors: onlyAnd: False\n",
      "getAuthorsAndEditors: nothing: False\n",
      "getAuthorsAndEditors: textBetweenNames: . (Eds.), Nuclear Energy Today. Publisher Name.\n",
      "getAuthorsAndEditors: Author: H\n",
      "getAuthorsAndEditors: onlyPunctuation: False\n",
      "getAuthorsAndEditors: onlyAnd: False\n",
      "getAuthorsAndEditors: nothing: True\n",
      "getAuthorsAndEditors: authorsDetected: False\n",
      "getAuthorsAndEditors: is_Editor: True\n",
      "getAuthorsAndEditors: chainStartIndex: 84\n",
      "getAuthorsAndEditors: return: ([0, 38], [84, 110])\n",
      "authors : Singh, S. K., Kumar, S., & Mehra, P. S\n",
      "surenameFirst: False\n",
      "Fall ., Singh, S. K., Kumar, S., & Mehra, P. S\n",
      "editors : Johnson, E. F. & Lee, R. H\n",
      "surenameFirst: False\n",
      "Fall , Johnson, E. F. & Lee, R. H\n",
      "Singh, S. K., Kumar, S., & Mehra, P. S. (2023). An new model for nuclear Energy. In, Eds.), Nuclear Energy Today. Publisher Name\n",
      "finalAuthors: S. K. Singh and S. Kumar and P. S. Mehra\n",
      "finalEditors: E. F. Johnson and R. H Lee\n"
     ]
    }
   ],
   "source": [
    "text = \"Singh, S. K., Kumar, S., & Mehra, P. S. (2023). An new model for nuclear Energy. In Johnson, E. F. & Lee, R. H. (Eds.), Nuclear Energy Today. Publisher Name.\"\n",
    "\n",
    "\n",
    "def find_First_Term(text, search_terms):\n",
    "    # Initialisiere mit einem hohen Wert\n",
    "    min_index = float('inf')\n",
    "    end_index = 0\n",
    "    andTyp = \"\"\n",
    "    \n",
    "    # Suche jeden Suchbegriff in dem Text und behalte den kleinsten Index\n",
    "    for term in search_terms:\n",
    "        index = text.find(term)\n",
    "        if index != -1 and index < min_index:\n",
    "            min_index = index\n",
    "            end_index = min_index + len(term) - 1\n",
    "            andTyp = term\n",
    "    \n",
    "    # Wenn min_index unverändert ist, wurde keiner der Begriffe gefunden\n",
    "    return (min_index, end_index, andTyp) if min_index != float('inf') else (-1, -1, \"\")\n",
    "\n",
    "def is_SurenameFirst(names):\n",
    "    if re.search(r'^(\\w+\\.)', names) or re.search(r'^(\\w+\\s\\w+(.,)?)+$', names):\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "def is_NameShortened(df_PER):\n",
    "    for index in df_PER.index.values.tolist():\n",
    "        if \".\" == text[df_PER[\"end\"].iloc[index]] and len(text[df_PER[\"start\"].iloc[index]:df_PER[\"end\"].iloc[index] + 1]) == 2:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def getIndexOfSubstring(regEx, text):\n",
    "    if re.search(regEx, text):\n",
    "        x = re.search(editorRegEx, text)\n",
    "        return (x.start(), x.end())\n",
    "    else:\n",
    "        return(-1,-1)\n",
    "\n",
    "def is_punctuation(s):\n",
    "    allowed_chars = string.punctuation.replace('&', '') + ' '\n",
    "    return all(char in allowed_chars for char in s)\n",
    "\n",
    "def is_Editor(editorRegEx, textBetweenNames, index):\n",
    "    if re.search(editorRegEx, textBetweenNames):\n",
    "        x = re.search(editorRegEx, text)\n",
    "        #print(f'x: {x.start()}')\n",
    "        if is_punctuation(text[index:x.start()]):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def extract_Names(authors):\n",
    "    finalAuthors = \"\"\n",
    "    search_terms = [\" and \", \", and \", \" & \", \", & \"]\n",
    "    andInAuthors = find_First_Term(authors, search_terms)[2]\n",
    "    surenameFirst = is_SurenameFirst(authors)\n",
    "    print(f'surenameFirst: {surenameFirst}')\n",
    "    if surenameFirst:\n",
    "        #hier völlig egal, ob er einzelne Initialen in ein eigenes Word gesteckt hat, obwohl es noch Nachnamen gib\n",
    "        authors = authors.replace(andInAuthors, \" and \")\n",
    "        print(f'authors: {authors}')\n",
    "        finalAuthors = authors.replace(\", \", \" and \")\n",
    "    elif andInAuthors != \"\":\n",
    "        if \"., \" in authors:\n",
    "            print(\"Fall ., {0}\".format(authors))\n",
    "            search_terms = [\"., and \", \"., & \", \". and \", \". & \"]\n",
    "            andInAuthors = find_First_Term(authors, search_terms)[2]\n",
    "            authors = authors.replace(andInAuthors, \"., \")\n",
    "            authors = authors.split(\"., \")\n",
    "            authors = [name + \".\" for name in authors]\n",
    "            authors = [name.replace(\"..\",\".\") for name in authors]\n",
    "            for author in authors[:-1]:\n",
    "                buffer = author.split(\", \")\n",
    "                finalAuthors = finalAuthors + buffer[1] + \" \" + buffer[0] + \" and \"\n",
    "            buffer = authors[-1].split(\", \")\n",
    "            finalAuthors = finalAuthors + buffer[1] + \" \" +  buffer[0]\n",
    "        elif \", \" in authors:\n",
    "            print(\"Fall , {0}\".format(authors))\n",
    "            search_terms = [\", and \", \", & \", \" and \", \" & \"]\n",
    "            andInAuthors = find_First_Term(authors, search_terms)[2]\n",
    "            authors = authors.replace(andInAuthors, \", \")\n",
    "            authors = authors.split(\", \")\n",
    "            for i in range(0, len(authors) - 3, 2):\n",
    "                finalAuthors = finalAuthors + authors[i+1] + \" \" + authors[i] + \" and \"\n",
    "            finalAuthors = finalAuthors + authors[len(authors) - 1] + \" \" + authors[len(authors) - 2]\n",
    "    else:\n",
    "        print(\"Fall else {0}\".format(authors))\n",
    "        authors = authors.split(\", \")\n",
    "        finalAuthros = authors[1] + authors[0]\n",
    "    return finalAuthors\n",
    "\n",
    "def getAuthorsAndEditors(df_PER, text):\n",
    "    search_terms = [\" and \", \", and \", \" & \", \", & \", \"., & \", \"., and \", \". and \", \". & \"]\n",
    "    editorRegEx = \" (\\()?(Eds\\.|Eds|Ed|ed|Ed\\.|ed\\.|eds\\.|editor|editors)(\\))?\"\n",
    "    index_df_PER_List = df_PER.index.values.tolist()\n",
    "    onlyPunctuation = False\n",
    "    onlyAnd = False\n",
    "    authorsDetected = False\n",
    "    setChainStart = True\n",
    "    startIndexAuthors = -1\n",
    "    endIndexAuthors = -1\n",
    "    startIndexEditors = -1\n",
    "    endIndexEditors = -1\n",
    "    chainStartIndex = -1\n",
    "\n",
    "\n",
    "    for index in index_df_PER_List:\n",
    "        #beachte: Hiermit lese ich immer schon vor!\n",
    "        if index < len(index_df_PER_List) - 1:\n",
    "            textBetweenNames = text[df_PER[\"end\"].iloc[index]:df_PER[\"start\"].iloc[index + 1]]\n",
    "        else:\n",
    "            textBetweenNames = text[df_PER[\"end\"].iloc[index]:]\n",
    "        onlyPunctuation = is_punctuation(textBetweenNames)\n",
    "        print(f'getAuthorsAndEditors: textBetweenNames: {textBetweenNames}')\n",
    "        print(f'getAuthorsAndEditors: Author: {text[df_PER[\"start\"].iloc[index]:df_PER[\"end\"].iloc[index]]}')\n",
    "        print(f'getAuthorsAndEditors: onlyPunctuation: {onlyPunctuation}')\n",
    "        firstStartIndex, firstEndIndex, andTyp = find_First_Term(textBetweenNames, search_terms)\n",
    "        onlyAnd = textBetweenNames == andTyp\n",
    "        print(f'getAuthorsAndEditors: onlyAnd: {onlyAnd}')\n",
    "        print(f'getAuthorsAndEditors: nothing: {not onlyAnd and not onlyPunctuation}')\n",
    "        if setChainStart: \n",
    "            chainStartIndex = df_PER[\"start\"].iloc[index]\n",
    "            #Solange das auf False, sollen der Substring erweitert werden, also start bleibt konstant\n",
    "            #print(f'chainStartIndex: {chainStartIndex}')\n",
    "            setChainStart = False\n",
    "        #Dann gab es einen Bruch in der Autorenkette. Also bin ich in einer Lücke zwischen den AUtoren\n",
    "        #Dann ist Nächster Block wieder ein Autor\n",
    "        if not onlyPunctuation and not onlyAnd:\n",
    "            setChainStart = True\n",
    "            #Es können auch nur Editoren und keine Autoren vorkommen\n",
    "            authorsDetected = not is_Editor(editorRegEx, textBetweenNames, df_PER[\"end\"].iloc[index])\n",
    "            print(f'getAuthorsAndEditors: authorsDetected: {authorsDetected}')\n",
    "            print(f'getAuthorsAndEditors: is_Editor: {is_Editor(editorRegEx, textBetweenNames, df_PER[\"end\"].iloc[index])}')\n",
    "            print(f'getAuthorsAndEditors: chainStartIndex: {chainStartIndex}')\n",
    "            # endIndexAuthors == -1, damit Autoren im Titel nicht wieder als Autoren erkannt werden\n",
    "            if authorsDetected and endIndexAuthors == -1:\n",
    "                startIndexAuthors = chainStartIndex\n",
    "                endIndexAuthors = df_PER[\"end\"].iloc[index]\n",
    "            #nicht nur ein else, falls Namen im Titel des Buches auftauchen\n",
    "            elif is_Editor(editorRegEx, textBetweenNames, df_PER[\"end\"].iloc[index]):\n",
    "                startIndexEditors = chainStartIndex\n",
    "                endIndexEditors = df_PER[\"end\"].iloc[index]\n",
    "                break\n",
    "    print(f'getAuthorsAndEditors: return: {[startIndexAuthors,endIndexAuthors],[startIndexEditors, endIndexEditors]}')\n",
    "    return [[startIndexAuthors,endIndexAuthors],[startIndexEditors, endIndexEditors]]\n",
    "\n",
    "def replaceSubstring (startIndex, endIndex, text, substituteString):\n",
    "    startIndexReplace = -1\n",
    "    endIndexReplace = -1\n",
    "    if startIndex > 0:\n",
    "        for i in range(startIndex - 1, 0, -1):\n",
    "            if not is_punctuation(text[i]):\n",
    "                startIndexReplace = i + 1\n",
    "                break\n",
    "    else:\n",
    "        startIndexReplace = 0\n",
    "        substituteString = ''\n",
    "    for i in range(endIndex, len(text) - 1, 1):\n",
    "        if not is_punctuation(text[i]):\n",
    "            endIndexReplace = i\n",
    "            break\n",
    "    text = text[0:startIndexReplace] + substituteString + text[endIndexReplace:len(text) - 1]\n",
    "    return text\n",
    "\n",
    "\n",
    "#search_terms = [\", et al.\", \" et al.\"]\n",
    "#firstStartIndex, firstEndIndex, etAl = find_First_Term(text, search_terms)\n",
    "#if firstStartIndex > -1:\n",
    "    #text = replaceSubstring(firstStartIndex, firstEndIndex, text, \", \")\n",
    "\n",
    "\n",
    "ner_tagger = pipeline(\"ner\", aggregation_strategy=\"simple\")\n",
    "print(text)\n",
    "outputs = ner_tagger(text)\n",
    "df_outputs = pd.DataFrame(outputs)\n",
    "print(df_outputs)\n",
    "#index neu setzen, da diese nicht automatich geupdates werden\n",
    "df_PER = df_outputs[df_outputs[\"entity_group\"] == \"PER\"].reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(df_PER)\n",
    "\n",
    "finalAuthors = \"\"\n",
    "finalEditors = \"\"\n",
    "auhtorsAndEditorsIndices = getAuthorsAndEditors(df_PER, text)\n",
    "if auhtorsAndEditorsIndices[0][0] > -1:\n",
    "    authors = text[auhtorsAndEditorsIndices[0][0]:auhtorsAndEditorsIndices[0][1]]\n",
    "    print(f'authors : {authors}')\n",
    "    finalAuthors = extract_Names(authors)\n",
    "    #text = replaceSubstring(auhtorsAndEditorsIndices[0][0], auhtorsAndEditorsIndices[0][1], text, \"\")\n",
    "\n",
    "\n",
    "if auhtorsAndEditorsIndices[1][0] > -1:\n",
    "    editors = text[auhtorsAndEditorsIndices[1][0]:auhtorsAndEditorsIndices[1][1]]\n",
    "    print(f'editors : {editors}')\n",
    "    finalEditors = extract_Names(editors)\n",
    "    text = replaceSubstring(auhtorsAndEditorsIndices[1][0], auhtorsAndEditorsIndices[1][1], text, \", \")\n",
    "    indicesEditorMarker = getIndexOfSubstring(editorRegEx, text)\n",
    "    #text = replaceSubstring(indicesEditorMarker[0], indicesEditorMarker[1], text, \", \")\n",
    "\n",
    "print(text)\n",
    "print(f'finalAuthors: {finalAuthors}')\n",
    "print(f'finalEditors: {finalEditors}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a1358ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "firstEndIndex edited by: 68\n",
      "editedBy: False\n",
      "x: <re.Match object; span=(59, 62), match=' ed'>\n"
     ]
    }
   ],
   "source": [
    "        firstStartIndex, firstEndIndex, editorTyp = find_First_Term(text, [\" edited by \"])\n",
    "        print(f'firstEndIndex edited by: {firstEndIndex}')\n",
    "        if firstStartIndex > -1 and index < len(index_df_PER_List) - 1:\n",
    "            print(f'df_PER[\"start\"].iloc[index]: {df_PER[\"start\"].iloc[index + 1]}')\n",
    "            editedBy = firstEndIndex + 1 == df_PER[\"start\"].iloc[index + 1]\n",
    "            #hier kam es oft vor, dass NER die Namen nicht richtig erkennt. Daher Sonderprüfung\n",
    "            if not editedBy:\n",
    "                buffer = text[firstEndIndex + 1:df_PER[\"start\"].iloc[index + 1]]\n",
    "                if re.search(r'^[A-Za-z]\\.([ ][A-Za-z]\\.)*[ ]?$', buffer):\n",
    "                    editedBy = True\n",
    "        print(f'editedBy: {editedBy}')\n",
    "        if editedBy:\n",
    "            startIndexEditorMarker = firstStartIndex\n",
    "            endIndexEditorMarker = firstEndIndex\n",
    "            editorsDetected = True\n",
    "        else:\n",
    "            print(f'x: {re.search(editorRegEx, text)}')\n",
    "            \n",
    "            \n",
    "  \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11af99c",
   "metadata": {},
   "source": [
    "Idee: Nun zunächst Jahr, Volume, Seiten, Edition und URL/DOI extrahieren. Den Rest (also Titel, Publisher, Series), dann nochmal den SpacyParer drüber laufen lassen, weil "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adc72533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 22, 'edited by')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  entity_group     score          word  start  end\n",
      "0         MISC  0.871492          Book      5    9\n",
      "1          PER  0.999499  Martin Trump     24   36\n"
     ]
    }
   ],
   "source": [
    "s = \"This Book was edited by Martin Trump\" \n",
    "print(find_First_Term(s, [\"edited by\"]))\n",
    "ner_tagger = pipeline(\"ner\", aggregation_strategy=\"simple\")\n",
    "text = s\n",
    "outputs = ner_tagger(text)\n",
    "df_outputs = pd.DataFrame(outputs)\n",
    "print(df_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad04c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test, um Datum Zuverlässig erkannt wird\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Hinton, G., Bengio, Y. and LeCun, Y. (2021). Deep Learning for Artificial Intelligence. In J. Smith & J. Doe (Eds.), Proceedings of the IEEE International Conference on Neural Networks (Vol. 1, Issue 5, pp. 100–120). IEEE Press. https://doi.org/10.1109/ICNN.2021.9483948\")\n",
    "for ent in doc.ents:\n",
    "  print(ent, ent.start_char-ent.sent.start_char, ent.end_char-ent.sent.start_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d86d914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Y. and LeCun, Y. (2021). Deep Learning for Artificial Intelligence. In J. Smith & J. Doe (Eds.), Proceedings of the IEEE International Conference on Neural Networks (Vol. 1, Issue 5, pp. 100–120). IEEE Press. https://doi.org/10.1109/ICNN.2021.948394\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \"Hinton, G., Bengio, Y. and LeCun, Y. (2021). Deep Learning for Artificial Intelligence. In J. Smith & J. Doe (Eds.), Proceedings of the IEEE International Conference on Neural Networks (Vol. 1, Issue 5, pp. 100–120). IEEE Press. https://doi.org/10.1109/ICNN.2021.9483948\"\n",
    "startIndex = 0\n",
    "endIndex = 18\n",
    "startIndexReplace = -1\n",
    "endIndexReplace = -1\n",
    "if startIndex > 0:\n",
    "    for i in range(startIndex - 1, 0, -1):\n",
    "        if not is_punctuation(text[i]):\n",
    "            startIndexReplace = i + 1\n",
    "            break\n",
    "else:\n",
    "    startIndexReplace = 0\n",
    "for i in range(endIndex, len(text) - 1, 1):\n",
    "    if not is_punctuation(text[i]):\n",
    "        endIndexReplace = i\n",
    "        break\n",
    "text = text[0:startIndexReplace] + \"#\" + text[endIndexReplace:len(text) - 1]\n",
    "print (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9aaa11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
