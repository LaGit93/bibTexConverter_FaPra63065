{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9ef1f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wenn man den typen bestimmte hat, sollte man zunächst alle Pflicht-Felder des Bibtex-Eintrages raussuchen und bestimmen.\n",
    "#Dazu die Pflichtattribute in einer Schleife durchgehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bde3f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "torch.cuda.is_available()\n",
    "from transformers import pipeline\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad55d2b1",
   "metadata": {},
   "source": [
    "@book{advanced_physics, author = {Stephen Hawking and Brian Greene and Maria Trump and Susan Soy}, title = {Advanced Concepts in Theoretical Physics}, publisher = {Cambridge University Press}, year = {2025}, edition = {3}, volume = {1}, series = {Advanced Studies in Physics}, address = {Cambridge, UK}, month = {May}, note = {A seminal work in the field of theoretical physics}, isbn = {978-0-521-76948-0}, doi = {10.1017/example.book.2025}, url = {https://www.cambridge.org/advanced_physics}, annote = {Widely cited in the physics community}, abstract = {This book explores cutting-edge theories and concepts in theoretical physics...}, keywords = {Theoretical Physics, Quantum Mechanics, String Theory}, language = {English}, price = {75.00}, size = {600 pages}, lccn = {2020934576}, mrnumber = {MR3070071} }\n",
    "\n",
    "@article{quantum_entanglement,\n",
    "  author        = {Albert Einstein and Boris Podolsky and Nathan Rosen},\n",
    "  title         = {Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?},\n",
    "  journal       = {Physical Review},\n",
    "  year          = {1935},\n",
    "  volume        = {47},\n",
    "  number        = {10},\n",
    "  pages         = {777-780},\n",
    "  month         = {May},\n",
    "  note          = {EPR Paradox paper, fundamental for quantum mechanics},\n",
    "  doi           = {10.1103/PhysRev.47.777},\n",
    "  url           = {https://journals.aps.org/pr/abstract/10.1103/PhysRev.47.777},\n",
    "  abstract      = {In this paper, the authors discuss the EPR paradox and challenge the completeness of quantum mechanics...},\n",
    "  keywords      = {Quantum Mechanics, EPR Paradox, Physical Reality},\n",
    "  language      = {English},\n",
    "  publisher     = {American Physical Society}\n",
    "}\n",
    "\n",
    "@inproceedings{deep_learning,\n",
    "  author        = {Geoffrey Hinton and Yoshua Bengio and Yann LeCun},\n",
    "  title         = {Deep Learning for Artificial Intelligence},\n",
    "  booktitle     = {Proceedings of the IEEE International Conference on Neural Networks},\n",
    "  year          = {2021},\n",
    "  editor        = {Jane Smith and John Doe},\n",
    "  volume        = {1},\n",
    "  number = {5},\n",
    "  series        = {Advances in Neural Information Processing},\n",
    "  pages         = {100-120},\n",
    "  address       = {Montreal, Canada},\n",
    "  month         = {December},\n",
    "  organization  = {IEEE},\n",
    "  publisher     = {IEEE Press},\n",
    "  note          = {Keynote paper on recent advancements in deep learning},\n",
    "  isbn          = {978-1-5386-4637-1},\n",
    "  doi           = {10.1109/ICNN.2021.9483948},\n",
    "  url           = {https://ieeexplore.ieee.org/document/9483948},\n",
    "  annote        = {A seminal work on how deep learning transforms AI},\n",
    "  abstract      = {This paper explores cutting-edge deep learning techniques and their impact on the development of artificial intelligence...},\n",
    "  keywords      = {Deep Learning, Artificial Intelligence, Neural Networks},\n",
    "  language      = {English}\n",
    "}\n",
    "\n",
    "\n",
    "@incollection{quantum_computation,\n",
    "  author        = {Michael A. Nielsen and Isaac L. Chuang},\n",
    "  title         = {Quantum Computation and Quantum Information},\n",
    "  booktitle     = {Handbook of Quantum Information Science},\n",
    "  publisher     = {Springer},\n",
    "  year          = {2026},\n",
    "  editor        = {Charles H. Bennett and David P. DiVincenzo},\n",
    "  volume        = {4},\n",
    "  series        = {Quantum Science and Technology},\n",
    "  chapter       = {10},\n",
    "  pages         = {250-300},\n",
    "  address       = {Berlin, Germany},\n",
    "  month         = {October},\n",
    "  note          = {A comprehensive overview of the fundamentals of quantum computation},\n",
    "  isbn          = {978-3-540-88702-7},\n",
    "  doi           = {10.1007/springerreference_303198},\n",
    "  url           = {https://www.springer.com/gp/book/9783540887027},\n",
    "  annote        = {Essential reading for researchers entering the field of quantum information},\n",
    "  abstract      = {This chapter delves into the principles of quantum computing, offering an accessible yet thorough introduction...},\n",
    "  keywords      = {Quantum Computing, Quantum Information, Computational Models},\n",
    "  language      = {English},\n",
    "  price         = {45.00},\n",
    "  size          = {50 pages}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b93a7979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(94, 100), match='(Eds.)'>\n"
     ]
    }
   ],
   "source": [
    "#RegEx zum FInden der Seiten\n",
    "pageFinder = \", (?:pp\\.? )?\\d+-\\d+,\"\n",
    "doiUrl = \"https:\\/\\/doi\\.org(\\/[^\\s]*)?$\"\n",
    "doiUrl2 = \"DOI:(https:\\/\\/doi\\.org)?([^\\s]*)+$\"\n",
    "url = \"https:\\/\\/[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}(\\/[^\\s]*)?$\"\n",
    "doi2 = \"DOI:\"\n",
    "\n",
    "#if havard und book:\n",
    "volume = \", \\d+,\"\n",
    "number = \", \\d+,\"\n",
    "edition1 = \"(?:[1-9]\\d*th|11th|12th|13th|[1-9]\\d*(?:st|nd|rd)) ed\\.\"\n",
    "edition2 = \"(?:[1-9]\\d*th|11th|12th|13th|[1-9]\\d*(?:st|nd|rd)) edn\\.\"\n",
    "\n",
    "#if APA or Havard then\n",
    "volume = \"\\(Vol\\. \\d+\" #für Volume und number noch als Bedingung, dass es nach Titel stehen muss, also Index > Titel-Index\n",
    "number = \"Issue \\d+\"\n",
    "yearApaHavardRegEx = \"\\(\\d{4}\\)\"\n",
    "\n",
    "\n",
    "#editor bei anderen\n",
    "\n",
    "\n",
    "#Beachte: Editor und Edition werden oft mit gleichen Abkürzungen versehen, auch im gleichen Stil! Nur Edition wird oft\n",
    "#klein geschrieben. Daher zustzlich prüfen, ob NER das als Person erkennt.\n",
    "\n",
    "#Beachte: ieee und mla trennen mit , und nicht mit .\n",
    "#if ieee and mla\n",
    "volumeIeeeMla = \", vol\\. \\d+\" \n",
    "noIeeeMla = \", no\\. \\d+\"\n",
    "\n",
    "etAl = \"et al.\"\n",
    "\n",
    "yearACM = \"\\. \\d{4}\\.\"\n",
    "\n",
    "#Man sollte zunächst die Felder extrahieren, die zu 100% sicher erkennen kann wie Volume oder Number, doi, Autoren...-> \n",
    "#Titel, booktitle, series und journal danach\n",
    "\n",
    "#man sollte eine Überdeckungsprüfung machen: Also Bspw. sagt Space im Bereich 25-50 ist eine Orga, Regex sagt, \n",
    "#dort ist ein (Eds.)\n",
    "#zu finden und Huggingface sagt, von 25-45 ist was. Dann sollte der minimalteste Wert und maximalste Wert \n",
    "#genommen werden und so lange nach links und analog nach rechts gehen, bis wieder ein Punkt kommt.\n",
    "# Da erkannte Felder aus dem String entfernt werden, muss der String am Ende leer sein. \n",
    "#Daher sollten zunächste die Dinge ausgeschnitten werden wo der Algo sich am sichersten ist\n",
    "#TODO: Grundsätzliche Reihenfolge der BibTex-Einträge ermitteln.\n",
    "#TODO: Für jede Extrahierung eines Feldes eine eigene Unterroutine schreiben? -> In der Oberschleife sollte Style sein\n",
    "\n",
    "\n",
    "\n",
    "print(re.search(editorRegEx, \"Singh, S. K., Kumar, S., & Mehra, P. S. (2023). Chapter Title. In Johnson, E. F. & Lee, R. H. (Eds.), Book\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddfd2554",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"Hawking, S., Greene, B., Trump, M. and Soy, S. (2025). Advanced Concepts in Theoretical Physics (3rd ed., Vol. 1, no. 5). In Johnson, E. F. & Lee, R. H. (Eds.), Nuclear Energy Today. Cambridge University Press. https://doi.org/10.1017/example.book.2025\"\n",
    "text = \"Singh, S. K., Kumar, S., & Mehra, P. S. (2023). Chat GPT & Google Bard AI: A Review. 2023 International Conference on IoT, Communication and Automation Technology (ICICAT), 1–6. https://doi.org/10.1109/ICICAT57735.2023.10263706\"\n",
    "text = \"Singh, S. K., Kumar, S., & Mehra, P. S. (2023). An new model for nuclear Energy. In Johnson, E. F. & Lee, R. H. (Eds.), Nuclear Energy Today. Publisher Name.\"\n",
    "#text = \"Singh, S. K. and Peterman, P. (2023). Chapter and Title. Trump, M. and Soy, S. Book Title. Publisher Name.\"\n",
    "#text = \"S. K. Singh, S. Kumar & P. S. Mehra, (2023). in Wonderland. In F. Johnson & L. Lee (Eds.), Book Title. Publisher Name.\"\n",
    "#text = \"F Johnson & L Lee (Eds.)\"\n",
    "#text = \"Tu Anh Nguyen, Eugene Kharitonov, Jade Copet, Yossi Adi, Wei-Ning Hsu, Ali Elkahky, Paden Tomasello, Robin Algayres, Benoît Sagot, Abdelrahman Mohamed, and Emmanuel Dupoux. 2023. Generative spoken dialogue language modeling. Transactions of the Association for Computational Linguistics 11, (2023), 250–266. URL: https://aclanthology.org/2023.tacl-1.15, doi:10.1162/tacl_a_00545\"\n",
    "#text = \"Hinton G, Bengio Y, LeCun Y (2021) Deep Learning for Artificial Intelligence. In: Smith J, Doe J (eds) Proceedings of the IEEE International Conference on Neural Networks. IEEE Press, Montreal, Canada, pp 100–120\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8acde04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "C:\\Users\\larsl\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hawking, S., Greene, B., Trump, M. and Soy, S. (2025). Advanced Concepts in Theoretical Physics (3rd ed., Vol. 1, no. 5). In Johnson, E. F. & Lee, R. H. (Eds.), Nuclear Energy Today. Cambridge University Press. https://doi.org/10.1017/example.book.2025\n",
      "   entity_group     score                        word  start  end\n",
      "0           PER  0.991428                     Hawking      0    7\n",
      "1           PER  0.998555                           S      9   10\n",
      "2           PER  0.999765                      Greene     13   19\n",
      "3           PER  0.998674                           B     21   22\n",
      "4           PER  0.999709                       Trump     25   30\n",
      "5           PER  0.998105                           M     32   33\n",
      "6           PER  0.987345                         Soy     39   42\n",
      "7           PER  0.998900                           S     44   45\n",
      "8          MISC  0.651478              ##ical Physics     83   95\n",
      "9           PER  0.999629                     Johnson    125  132\n",
      "10          PER  0.996778                           E    134  135\n",
      "11          PER  0.995004                           F    137  138\n",
      "12          PER  0.998882                         Lee    142  145\n",
      "13          PER  0.997605                           R    147  148\n",
      "14          PER  0.991540                           H    150  151\n",
      "15         MISC  0.510577                     Nuclear    161  168\n",
      "16          ORG  0.821604                      Energy    169  175\n",
      "17         MISC  0.768082                       Today    176  181\n",
      "18          ORG  0.981617  Cambridge University Press    183  209\n",
      "   entity_group     score     word  start  end\n",
      "0           PER  0.991428  Hawking      0    7\n",
      "1           PER  0.998555        S      9   10\n",
      "2           PER  0.999765   Greene     13   19\n",
      "3           PER  0.998674        B     21   22\n",
      "4           PER  0.999709    Trump     25   30\n",
      "5           PER  0.998105        M     32   33\n",
      "6           PER  0.987345      Soy     39   42\n",
      "7           PER  0.998900        S     44   45\n",
      "8           PER  0.999629  Johnson    125  132\n",
      "9           PER  0.996778        E    134  135\n",
      "10          PER  0.995004        F    137  138\n",
      "11          PER  0.998882      Lee    142  145\n",
      "12          PER  0.997605        R    147  148\n",
      "13          PER  0.991540        H    150  151\n",
      "startIndexReplace : 0\n",
      "endIndexReplace : 47\n",
      "text after replace authors : (2025). Advanced Concepts in Theoretical Physics (3rd ed., Vol. 1, no. 5). In Johnson, E. F. & Lee, R. H. (Eds.), Nuclear Energy Today. Cambridge University Press. https://doi.org/10.1017/example.book.2025\n",
      "Fall ., Hawking, S., Greene, B., Trump, M. and Soy, S. \n",
      "startIndexReplace : 77\n",
      "endIndexReplace : 106\n",
      "text after replace editors : (2025). Advanced Concepts in Theoretical Physics (3rd ed., Vol. 1, no. 5). In (Eds.), Nuclear Energy Today. Cambridge University Press. https://doi.org/10.1017/example.book.2025\n",
      "endIndexEditors : 75\n",
      "startIndexEditorMarker : 77\n",
      "Fall ,  Johnson, E. F. & Lee, R. H. \n",
      "startIndexReplace : 77\n",
      "endIndexReplace : 86\n",
      "text after replace EditorMarker : (2025). Advanced Concepts in Theoretical Physics (3rd ed., Vol. 1, no. 5). In. Nuclear Energy Today. Cambridge University Press. https://doi.org/10.1017/example.book.2025\n",
      "\n",
      "doiUrlRegEx: https:\\/\\/doi\\.org(\\/[^\\s]*)?$\n",
      "startIndexReplace : 127\n",
      "endIndexReplace : 170\n",
      "text after replace DOI: (2025). Advanced Concepts in Theoretical Physics (3rd ed., Vol. 1, no. 5). In. Nuclear Energy Today. Cambridge University Press.\n",
      "text after replace DOI: (2025). Advanced Concepts in Theoretical Physics (3rd ed., Vol. 1, no. 5). In. Nuclear Energy Today. Cambridge University Press.\n",
      "startIndexReplace : 0\n",
      "endIndexReplace : 8\n",
      "text after replace Page: Advanced Concepts in Theoretical Physics (3rd ed., Vol. 1, no. 5). In. Nuclear Energy Today. Cambridge University Press.\n",
      "startIndexReplace : 57\n",
      "endIndexReplace : 64\n",
      "text after replace Number: Advanced Concepts in Theoretical Physics (3rd ed., Vol. 1.). In. Nuclear Energy Today. Cambridge University Press.\n",
      "startIndexReplace : 48\n",
      "endIndexReplace : 58\n",
      "text after replace Volume: Advanced Concepts in Theoretical Physics (3rd ed.). In. Nuclear Energy Today. Cambridge University Press.\n",
      "startIndexReplace : 40\n",
      "endIndexReplace : 49\n",
      "text after replace Edition: Advanced Concepts in Theoretical Physics.). In. Nuclear Energy Today. Cambridge University Press.\n",
      "\n",
      "finalAuthors: S. Hawking and B. Greene and M. Trump and S. . Soy\n",
      "finalEditors: E. F.  Johnson and R. H.  Lee\n",
      "finalDoi: . https://doi.org/10.1017/example.book.2025\n",
      "finalYear: (2025). \n",
      "finalNumber: , no. 5\n",
      "finalVolume: ., Vol. 1.\n",
      "finalEdition:  (3rd ed.\n",
      "finalPage: 0\n",
      "finalURL: 0\n"
     ]
    }
   ],
   "source": [
    "text=\"Hawking, S., Greene, B., Trump, M. and Soy, S. (2025). Advanced Concepts in Theoretical Physics (3rd ed., Vol. 1, no. 5). In Johnson, E. F. & Lee, R. H. (Eds.), Nuclear Energy Today. Cambridge University Press. https://doi.org/10.1017/example.book.2025\"\n",
    "#text = \"Singh, S. K., Kumar, S., & Mehra, P. S. (2023). An new model for nuclear Energy. In Johnson, E. F. & Lee, R. H. (Eds.), Nuclear Energy Today. vol. 1, no. 5, IEEE Press, 2021, pp. 100–20, doi:10.1109/ICNN.2021.9483948.\"\n",
    "#text = \"Einstein, A., Podolsky, B., & Rosen, N. (1935). Can Quantum-Mechanical Description of Physical Reality Be Considered Complete? Physical Review, 47(10), 777–780. https://doi.org/10.1103/PhysRev.47.777\"\n",
    "doiUrlRegEx = \"https:\\/\\/doi\\.org(\\/[^\\s]*)?$\"\n",
    "doiUrlRegEx2 = \"(DOI|doi):(https:\\/\\/doi\\.org)?([^\\s]*)+$\"\n",
    "editorRegEx = \" (\\()?(Eds\\.|Eds|Ed|ed|Ed\\.|ed\\.|eds\\.|editor|editors)(\\))?\"\n",
    "yearApaHavardRegEx = \"\\(\\d{4}\\)\"\n",
    "yearACM = \"(\\.|,) \\d{4}(\\.|,)\"\n",
    "\n",
    "\n",
    "def find_First_Term(text, search_terms):\n",
    "    # Initialisiere mit einem hohen Wert\n",
    "    min_index = float('inf')\n",
    "    end_index = 0\n",
    "    andTyp = \"\"\n",
    "    \n",
    "    # Suche jeden Suchbegriff in dem Text und behalte den kleinsten Index\n",
    "    for term in search_terms:\n",
    "        index = text.find(term)\n",
    "        if index != -1 and index < min_index:\n",
    "            min_index = index\n",
    "            end_index = min_index + len(term) - 1\n",
    "            andTyp = term\n",
    "    \n",
    "    # Wenn min_index unverändert ist, wurde keiner der Begriffe gefunden\n",
    "    return (min_index, end_index, andTyp) if min_index != float('inf') else (-1, -1, \"\")\n",
    "\n",
    "def is_SurenameFirst(names):\n",
    "    if re.search(r'^(\\w+\\.)', names) or re.search(r'^(\\w+\\s\\w+(.,)?)+$', names):\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "def is_NameShortened(df_PER):\n",
    "    for index in df_PER.index.values.tolist():\n",
    "        if \".\" == text[df_PER[\"end\"].iloc[index]] and len(text[df_PER[\"start\"].iloc[index]:df_PER[\"end\"].iloc[index] + 1]) == 2:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def getIndexOfSubstring(text, regEx = [], reverse = False):\n",
    "    for regExElement in regEx:\n",
    "        matches = list(re.finditer(regExElement, text))\n",
    "        if matches:\n",
    "            if reverse:\n",
    "                match = matches[-1]\n",
    "            else:\n",
    "                match = matches[0]\n",
    "            return match.start(), match.end()\n",
    "    return -1,-1\n",
    "\n",
    "def is_punctuation(text, replaceCharacter = []):\n",
    "    allowed_chars = string.punctuation + ' '\n",
    "    for character in replaceCharacter:\n",
    "        allowed_chars = allowed_chars.replace(character, '')\n",
    "    return all(char in allowed_chars for char in text)\n",
    "\n",
    "def is_Editor(editorRegEx, textBetweenNames, index):\n",
    "    if re.search(editorRegEx, textBetweenNames):\n",
    "        x = re.search(editorRegEx, text)\n",
    "        #print(f'x: {x.start()}')\n",
    "        if is_punctuation(text[index:x.start()], [\"&\"]):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def processNames(authors):\n",
    "    finalAuthors = \"\"\n",
    "    search_terms = [\" and \", \", and \", \" & \", \", & \"]\n",
    "    andInAuthors = find_First_Term(authors, search_terms)[2]\n",
    "    surenameFirst = is_SurenameFirst(authors)\n",
    "    #print(f'surenameFirst: {surenameFirst}')\n",
    "    if surenameFirst:\n",
    "        #hier völlig egal, ob er einzelne Initialen in ein eigenes Word gesteckt hat, obwohl es noch Nachnamen gib\n",
    "        authors = authors.replace(andInAuthors, \" and \")\n",
    "        #print(f'authors: {authors}')\n",
    "        finalAuthors = authors.replace(\", \", \" and \")\n",
    "    elif andInAuthors != \"\":\n",
    "        if \"., \" in authors:\n",
    "            print(\"Fall ., {0}\".format(authors))\n",
    "            search_terms = [\"., and \", \"., & \", \". and \", \". & \"]\n",
    "            andInAuthors = find_First_Term(authors, search_terms)[2]\n",
    "            authors = authors.replace(andInAuthors, \"., \")\n",
    "            authors = authors.split(\"., \")\n",
    "            authors = [name + \".\" for name in authors]\n",
    "            authors = [name.replace(\"..\",\".\") for name in authors]\n",
    "            for author in authors[:-1]:\n",
    "                buffer = author.split(\", \")\n",
    "                finalAuthors = finalAuthors + buffer[1] + \" \" + buffer[0] + \" and \"\n",
    "            buffer = authors[-1].split(\", \")\n",
    "            finalAuthors = finalAuthors + buffer[1] + \" \" +  buffer[0]\n",
    "        elif \", \" in authors:\n",
    "            print(\"Fall , {0}\".format(authors))\n",
    "            search_terms = [\", and \", \", & \", \" and \", \" & \"]\n",
    "            andInAuthors = find_First_Term(authors, search_terms)[2]\n",
    "            authors = authors.replace(andInAuthors, \", \")\n",
    "            authors = authors.split(\", \")\n",
    "            for i in range(0, len(authors) - 3, 2):\n",
    "                finalAuthors = finalAuthors + authors[i+1] + \" \" + authors[i] + \" and \"\n",
    "            finalAuthors = finalAuthors + authors[len(authors) - 1] + \" \" + authors[len(authors) - 2]\n",
    "    else:\n",
    "        print(\"Fall else {0}\".format(authors))\n",
    "        authors = authors.split(\", \")\n",
    "        finalAuthros = authors[1] + authors[0]\n",
    "    return finalAuthors\n",
    "\n",
    "def getAuthorsAndEditors(df_PER, text):\n",
    "    search_terms = [\" and \", \", and \", \" & \", \", & \", \"., & \", \"., and \", \". and \", \". & \"]\n",
    "    editorRegEx = \" (\\()?(Eds\\.|Eds|Ed|ed|Ed\\.|ed\\.|eds\\.|editor|editors)(\\))?\"\n",
    "    index_df_PER_List = df_PER.index.values.tolist()\n",
    "    onlyPunctuation = False\n",
    "    onlyAnd = False\n",
    "    authorsDetected = False\n",
    "    setChainStart = True\n",
    "    startIndexAuthors = -1\n",
    "    endIndexAuthors = -1\n",
    "    startIndexEditors = -1\n",
    "    endIndexEditors = -1\n",
    "    chainStartIndex = -1\n",
    "\n",
    "\n",
    "    for index in index_df_PER_List:\n",
    "        #beachte: Hiermit lese ich immer schon vor!\n",
    "        if index < len(index_df_PER_List) - 1:\n",
    "            textBetweenNames = text[df_PER[\"end\"].iloc[index]:df_PER[\"start\"].iloc[index + 1]]\n",
    "        else:\n",
    "            textBetweenNames = text[df_PER[\"end\"].iloc[index]:]\n",
    "        onlyPunctuation = is_punctuation(textBetweenNames, [\"&\"])\n",
    "        #print(f'getAuthorsAndEditors: textBetweenNames: {textBetweenNames}')\n",
    "        #print(f'getAuthorsAndEditors: Author: {text[df_PER[\"start\"].iloc[index]:df_PER[\"end\"].iloc[index]]}')\n",
    "        #print(f'getAuthorsAndEditors: onlyPunctuation: {onlyPunctuation}')\n",
    "        firstStartIndex, firstEndIndex, andTyp = find_First_Term(textBetweenNames, search_terms)\n",
    "        onlyAnd = textBetweenNames == andTyp\n",
    "        #print(f'getAuthorsAndEditors: onlyAnd: {onlyAnd}')\n",
    "        #print(f'getAuthorsAndEditors: nothing: {not onlyAnd and not onlyPunctuation}')\n",
    "        if setChainStart: \n",
    "            chainStartIndex = df_PER[\"start\"].iloc[index]\n",
    "            #Solange das auf False, sollen der Substring erweitert werden, also start bleibt konstant\n",
    "            #print(f'chainStartIndex: {chainStartIndex}')\n",
    "            setChainStart = False\n",
    "        #Dann gab es einen Bruch in der Autorenkette. Also bin ich in einer Lücke zwischen den AUtoren\n",
    "        #Dann ist Nächster Block wieder ein Autor\n",
    "        if not onlyPunctuation and not onlyAnd:\n",
    "            setChainStart = True\n",
    "            #Es können auch nur Editoren und keine Autoren vorkommen\n",
    "            authorsDetected = not is_Editor(editorRegEx, textBetweenNames, df_PER[\"end\"].iloc[index])\n",
    "            #print(f'getAuthorsAndEditors: authorsDetected: {authorsDetected}')\n",
    "            #print(f'getAuthorsAndEditors: is_Editor: {is_Editor(editorRegEx, textBetweenNames, df_PER[\"end\"].iloc[index])}')\n",
    "            #print(f'getAuthorsAndEditors: chainStartIndex: {chainStartIndex}')\n",
    "            # endIndexAuthors == -1, damit Autoren im Titel nicht wieder als Autoren erkannt werden\n",
    "            if authorsDetected and endIndexAuthors == -1:\n",
    "                startIndexAuthors = chainStartIndex\n",
    "                endIndexAuthors = df_PER[\"end\"].iloc[index]\n",
    "            #nicht nur ein else, falls Namen im Titel des Buches auftauchen\n",
    "            elif is_Editor(editorRegEx, textBetweenNames, df_PER[\"end\"].iloc[index]):\n",
    "                startIndexEditors = chainStartIndex\n",
    "                endIndexEditors = df_PER[\"end\"].iloc[index]\n",
    "                break\n",
    "    #print(f'getAuthorsAndEditors: return: {[startIndexAuthors,endIndexAuthors],[startIndexEditors, endIndexEditors]}')\n",
    "    return startIndexAuthors,endIndexAuthors,startIndexEditors, endIndexEditors\n",
    "\n",
    "def replaceSubstring (startIndex, endIndex, text, substituteString):\n",
    "    if endIndex > 0:\n",
    "        startIndexReplace = -1\n",
    "        endIndexReplace = -1\n",
    "        changedText = text\n",
    "        if startIndex > 0:\n",
    "            for i in range(startIndex - 1, 0, -1):\n",
    "                if not is_punctuation(text[i], [\"&\"]):\n",
    "                    startIndexReplace = i + 1\n",
    "                    break\n",
    "        else:\n",
    "            startIndexReplace = 0\n",
    "            substituteString = \"\"\n",
    "        print(f'startIndexReplace : {startIndexReplace}')\n",
    "        if endIndex < len(text):\n",
    "            for i in range(endIndex, len(text), 1):\n",
    "                if not is_punctuation(text[i], [\"&\", \"(\", \")\"]):\n",
    "                    endIndexReplace = i\n",
    "                    break\n",
    "        else:\n",
    "            endIndexReplace = len(text)\n",
    "        print(f'endIndexReplace : {endIndexReplace}')\n",
    "        changedText = text[0:startIndexReplace] + substituteString + text[endIndexReplace:len(text)]\n",
    "        return changedText, text[startIndexReplace:endIndexReplace]\n",
    "    return text, 0\n",
    "\n",
    "\n",
    "#search_terms = [\", et al.\", \" et al.\"]\n",
    "#firstStartIndex, firstEndIndex, etAl = find_First_Term(text, search_terms)\n",
    "#if firstStartIndex > -1:\n",
    "    #text = replaceSubstring(firstStartIndex, firstEndIndex, text, \", \")\n",
    "\n",
    "\n",
    "ner_tagger = pipeline(\"ner\", aggregation_strategy=\"simple\")\n",
    "print(text)\n",
    "outputs = ner_tagger(text)\n",
    "df_outputs = pd.DataFrame(outputs)\n",
    "print(df_outputs)\n",
    "#index neu setzen, da diese nicht automatich geupdates werden\n",
    "df_PER = df_outputs[df_outputs[\"entity_group\"] == \"PER\"].reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(df_PER)\n",
    "\n",
    "finalAuthors = \"\"\n",
    "finalEditors = \"\"\n",
    "startIndexAuthors,endIndexAuthors,startIndexEditors, endIndexEditors = getAuthorsAndEditors(df_PER, text)\n",
    "if startIndexAuthors > -1:\n",
    "    text, authors = replaceSubstring(startIndexAuthors, endIndexAuthors, text, \"\")\n",
    "    print(f'text after replace authors : {text}')\n",
    "    startIndexEditors = startIndexEditors - len(authors)\n",
    "    endIndexEditors = endIndexEditors - len(authors)\n",
    "    finalAuthors = processNames(authors)\n",
    "else:\n",
    "    startIndexAuthors, endIndexAuthors = 0, 0\n",
    "\n",
    "if startIndexEditors > -1:\n",
    "    text, editors = replaceSubstring(startIndexEditors, endIndexEditors, text, \" \")\n",
    "    endIndexEditors = endIndexEditors - len(editors)\n",
    "    print(f'text after replace editors : {text}')\n",
    "    print(f'endIndexEditors : {endIndexEditors}')\n",
    "    #es soll erst ab Editors gesucht werden, daher text[endIndexEditors:]. Sonst Verwechslungsgefahr\n",
    "    startIndexEditorMarker, endIndexEditorMarker = getIndexOfSubstring(text[endIndexEditors:], [editorRegEx])\n",
    "    startIndexEditorMarker = startIndexEditorMarker + endIndexEditors\n",
    "    endIndexEditorMarker = endIndexEditorMarker + endIndexEditors\n",
    "    print(f'startIndexEditorMarker : {startIndexEditorMarker}')\n",
    "    finalEditors = processNames(editors)\n",
    "    text, replacedEditorMarker = replaceSubstring(startIndexEditorMarker, endIndexEditorMarker, text, \". \")\n",
    "    print(f'text after replace EditorMarker : {text}')\n",
    "\n",
    "else:\n",
    "    startIndexEditors, endIndexEditors = 0, 0\n",
    "\n",
    "print(\"\")\n",
    "print(f'doiUrlRegEx: {doiUrlRegEx}')\n",
    "\n",
    "startIndex, endIndex = getIndexOfSubstring(text, [doiUrlRegEx, doiUrlRegEx2], True)\n",
    "text, finalDoi = replaceSubstring(startIndex, endIndex, text, \".\")\n",
    "print(f'text after replace DOI: {text}')\n",
    "\n",
    "urlRegEx = \"https?://[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}(?::\\d+)?(?:/[^\\s]*)?\"\n",
    "startIndex, endIndex = getIndexOfSubstring(text, [urlRegEx], True)\n",
    "text, finalURL = replaceSubstring(startIndex, endIndex, text, \".\")\n",
    "print(f'text after replace DOI: {text}')\n",
    "\n",
    "startIndex, endIndex = getIndexOfSubstring(text, [yearApaHavardRegEx, yearACM])\n",
    "text, finalYear = replaceSubstring(startIndex, endIndex, text, \".\")\n",
    "\n",
    "pageFinder = \"(?:pp\\.? )?\\d+(-|–)\\d+\"\n",
    "\n",
    "startIndex, endIndex = getIndexOfSubstring(text, [pageFinder], True)\n",
    "text, finalPage = replaceSubstring(startIndex, endIndex, text, \".\")\n",
    "\n",
    "print(f'text after replace Page: {text}')\n",
    "\n",
    "number1 = \" no\\. \\d+\"\n",
    "number2 = \" Issue \\d+\"\n",
    "number3 = \"\\d+\"\n",
    "\n",
    "#Volume, Seite, Number stehen IMMEr nach dem Titel. Also diese von Hinten suchen\n",
    "startIndex, endIndex = getIndexOfSubstring(text, [number1, number2, number3], True)\n",
    "text, finalNumber = replaceSubstring(startIndex, endIndex, text, \".\")\n",
    "\n",
    "print(f'text after replace Number: {text}')\n",
    "\n",
    "volume1 = \"Vol\\. \\d+\"\n",
    "volume2 = \"vol\\. \\d+\" \n",
    "volume3 = \"\\d+\"\n",
    "edition1 = \"(?:[1-9]\\d*th|11th|12th|13th|[1-9]\\d*(?:st|nd|rd)) ed\\.\"\n",
    "edition2 = \"(?:[1-9]\\d*th|11th|12th|13th|[1-9]\\d*(?:st|nd|rd)) edn\\.\"\n",
    "\n",
    "startIndex, endIndex = getIndexOfSubstring(text, [volume1, volume2, volume3], True)\n",
    "text, finalVolume = replaceSubstring(startIndex, endIndex, text, \".\")\n",
    "\n",
    "print(f'text after replace Volume: {text}')\n",
    "\n",
    "startIndex, endIndex = getIndexOfSubstring(text, [edition1, edition2], True)\n",
    "text, finalEdition = replaceSubstring(startIndex, endIndex, text, \".\")\n",
    "\n",
    "print(f'text after replace Edition: {text}')\n",
    "\n",
    "#if APA or Havard then\n",
    " #für Volume und number noch als Bedingung, dass es nach Titel stehen muss, also Index > Titel-Index\n",
    "\n",
    "#Beachte: Editor und Edition werden oft mit gleichen Abkürzungen versehen, auch im gleichen Stil! Nur Edition wird oft\n",
    "#klein geschrieben. Daher zustzlich prüfen, ob NER das als Person erkennt.\n",
    "\n",
    "#if ieee and mla\n",
    "\n",
    "\n",
    "# Auch alle Optionalen Felder mit aufzählen, auch wenn sie leer sind.\n",
    "print(\"\")\n",
    "print(f'finalAuthors: {finalAuthors}')\n",
    "print(f'finalEditors: {finalEditors}')\n",
    "print(f'finalDoi: {finalDoi}')\n",
    "print(f'finalYear: {finalYear}')\n",
    "print(f'finalNumber: {finalNumber}')\n",
    "print(f'finalVolume: {finalVolume}')\n",
    "print(f'finalEdition: {finalEdition}')\n",
    "print(f'finalPage: {finalPage}')\n",
    "print(f'finalURL: {finalURL}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a1358ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "firstEndIndex edited by: 68\n",
      "editedBy: False\n",
      "x: <re.Match object; span=(59, 62), match=' ed'>\n"
     ]
    }
   ],
   "source": [
    "        firstStartIndex, firstEndIndex, editorTyp = find_First_Term(text, [\" edited by \"])\n",
    "        print(f'firstEndIndex edited by: {firstEndIndex}')\n",
    "        if firstStartIndex > -1 and index < len(index_df_PER_List) - 1:\n",
    "            print(f'df_PER[\"start\"].iloc[index]: {df_PER[\"start\"].iloc[index + 1]}')\n",
    "            editedBy = firstEndIndex + 1 == df_PER[\"start\"].iloc[index + 1]\n",
    "            #hier kam es oft vor, dass NER die Namen nicht richtig erkennt. Daher Sonderprüfung\n",
    "            if not editedBy:\n",
    "                buffer = text[firstEndIndex + 1:df_PER[\"start\"].iloc[index + 1]]\n",
    "                if re.search(r'^[A-Za-z]\\.([ ][A-Za-z]\\.)*[ ]?$', buffer):\n",
    "                    editedBy = True\n",
    "        print(f'editedBy: {editedBy}')\n",
    "        if editedBy:\n",
    "            startIndexEditorMarker = firstStartIndex\n",
    "            endIndexEditorMarker = firstEndIndex\n",
    "            editorsDetected = True\n",
    "        else:\n",
    "            print(f'x: {re.search(editorRegEx, text)}')\n",
    "            \n",
    "            \n",
    "  \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11af99c",
   "metadata": {},
   "source": [
    "Idee: Nun zunächst Jahr, Volume, Seiten, Edition und URL/DOI extrahieren. Den Rest (also Titel, Publisher, Series), dann nochmal den SpacyParer drüber laufen lassen, weil "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adc72533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 22, 'edited by')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  entity_group     score          word  start  end\n",
      "0         MISC  0.871492          Book      5    9\n",
      "1          PER  0.999499  Martin Trump     24   36\n"
     ]
    }
   ],
   "source": [
    "s = \"This Book was edited by Martin Trump\" \n",
    "print(find_First_Term(s, [\"edited by\"]))\n",
    "ner_tagger = pipeline(\"ner\", aggregation_strategy=\"simple\")\n",
    "text = s\n",
    "outputs = ner_tagger(text)\n",
    "df_outputs = pd.DataFrame(outputs)\n",
    "print(df_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3ad04c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced Concepts 0 17 PERSON\n",
      "Theoretical Physics 21 40 ORG\n",
      "Today 0 5 DATE\n",
      "Cambridge University Press 0 26 ORG\n"
     ]
    }
   ],
   "source": [
    "#Test, um Datum Zuverlässig erkannt wird\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Advanced Concepts in Theoretical Physics (.). In. Nuclear Energy Today. Cambridge University Press.\")\n",
    "for ent in doc.ents:\n",
    "  print(ent, ent.start_char-ent.sent.start_char, ent.end_char-ent.sent.start_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d86d914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "vanced Concept\n"
     ]
    }
   ],
   "source": [
    "text = \"(2025). Advanced Concepts in Theoretical Physics (3rd ed., Vol. 1, no. 5). In (\"\n",
    "print(len(text))\n",
    "print(text[10:24])\n",
    "for i in range(24, 24, 1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9aaa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "doiUrl2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
